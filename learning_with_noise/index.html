<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3c.org/TR/1999/REC-html401-19991224/loose.dtd">
<html xml:lang="en" xmlns="http://www.w3.org/1999/xhtml" lang="en"><head>
  <title></title>
<meta http-equiv="Content-Type" content="text/html; charset=windows-1252">

<meta property="og:image" content="images/learning_with_noise.png"/>
<meta property="og:title" content="Learning to See by Looking at Noise" />

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-167124286-2', 'auto');
ga('send', 'pageview');
</script>
<script src="lib.js" type="text/javascript"></script>
<script src="popup.js" type="text/javascript"></script>

<script type="text/javascript">
// redefining default features
var _POPUP_FEATURES = 'width=500,height=300,resizable=1,scrollbars=1,titlebar=1,status=1';
</script>
<link media="all" href="glab.css" type="text/css" rel="StyleSheet">
<style type="text/css" media="all">
IMG {
	PADDING-RIGHT: 0px;
	PADDING-LEFT: 0px;
	FLOAT: right;
	PADDING-BOTTOM: 0px;
	PADDING-TOP: 0px
}
#primarycontent {
	MARGIN-LEFT: auto; ; WIDTH: expression(document.body.clientWidth >
1000? "1000px": "auto" ); MARGIN-RIGHT: auto; TEXT-ALIGN: left; max-width:
1000px }
BODY {
	TEXT-ALIGN: center
}
</style>

<style type="text/css">
  body {
    font-family: "Titillium Web","HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight:300;
    font-size:18px;
    margin-left: auto;
    margin-right: auto;
    margin-bottom: 0px;
    width: 100%;
  }

  h1 {
    font-weight:300;
  }

  div {
    max-width: 95%;
    margin:auto;
    padding: 10px;
  }

  .table-like {
    display: flex;
    flex-wrap: wrap;
    flex-flow: row wrap;
    justify-content: center;
  }

  .disclaimerbox {
    background-color: #eee;
    border: 1px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
    padding: 20px;
  }

  video.header-vid {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img {
    padding: 0;
    display: block;
    margin: 0 auto;
    max-height: 100%;
    max-width: 100%;
  }

  iframe {
    max-width: 100%;
  }

  img.header-img {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img.rounded {
    border: 1px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  a:link,a:visited
  {
    color: #1367a7;
    text-decoration: none;
  }
  a:hover {
    color: #208799;
  }

  td.dl-link {
    height: 160px;
    text-align: center;
    font-size: 22px;
  }

  .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
            15px 15px 0 0px #fff, /* The fourth layer */
            15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
            20px 20px 0 0px #fff, /* The fifth layer */
            20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
            25px 25px 0 0px #fff, /* The fifth layer */
            25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
    margin-left: 10px;
    margin-right: 45px;
  }


  .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
    margin-top: 5px;
    margin-left: 10px;
    margin-right: 30px;
    margin-bottom: 5px;
  }

  .vert-cent {
    position: relative;
      top: 50%;
      transform: translateY(-50%);
  }

  hr
  {
    border: 0;
    height: 1px;
    max-width: 1100px;
    background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
  }

  #authors td {
    padding-bottom:5px;
    padding-top:30px;
  }
</style>

<script>
  function resizeIframe(obj) {
    obj.style.height = obj.contentWindow.document.documentElement.scrollHeight + 'px';
  }
</script>

<body>

<div id="primarycontent">
<center><h1 style="font-size: 225%">Learning to See by Looking at Noise</h1></center>
<center>
  <!-- First row --->
  <div class="table-like" style="justify-content:space-evenly;max-width:880px;margin:auto;">
    <div width="1"></div>
    <div>
      <center>
        <a href="https://mbaradad.github.io/" style="font-size: larger">Manel Baradad*</a>
      </center>
      <center>
        MIT CSAIL
      </center>
    </div>
    <div width="1"></div>
    <div>
      <center>
        <a href="http://people.csail.mit.edu/jwulff/" style="font-size: larger">Jonas Wulff*</a>
      </center>
      <center>
        MIT CSAIL
      </center>
    </div>
    <div width="1"></div>
    <div>
      <center>
        <a href="https://ssnl.github.io" style="font-size: larger">Tongzhou Wang</a>
      </center>
      <center>
        MIT CSAIL
      </center>
    </div>
    <div width="1"></div>
  </div>

  <!-- Second row --->
  <div class="table-like" style="justify-content:space-evenly;max-width:880px;margin:auto;">
    <div width="1"></div>
    <div>
      <center>
        <a href="http://web.mit.edu/phillipi/" style="font-size: larger">Phillip Isola</a>
      </center>
      <center>
        MIT CSAIL
      </center>
    </div>
    <div>
      <center>
        <a href="https://groups.csail.mit.edu/vision/torralbalab/" style="font-size: larger">Antonio Torralba</a>
      </center>
      <center>
        MIT CSAIL
      </center>
    </div>
    <div width="1"></div>
  </div>
</center>
<br>

<center>
<table border="0" cellspacing="0" cellpadding="0">
  <tr>
    <td align="center" valign="bottom" width=900>
        <img class="result" src="images/teaser.jpeg" style="width: 100%">
    </td>
  </tr>
</table>
</center>


<div class="table-like" style="justify-content:space-evenly;max-width:900px;margin:auto;">
  <center>
    <table>
      <tr>
        <td style="font-size:20px;margin:20px;font-family:monospace">
          <a style="margin:2px" href="https://arxiv.org/abs/2106">[Paper]</a>
        </td>
        <td style="font-size:20px;margin:20px;font-family:monospace">
          <a style="margin:2px" href="https://github.com/mbaradad/learning_with_noise">[Code]</a>
        </td>
        <td style="font-size:20px;margin:20px;font-family:monospace">
          <a style="margin:2px" href="https://github.com/mbaradad/learning_with_noise">[Datasets]</a>
        </td>
      </tr>
    </table>
  </center>
</div>
<center>
<br>

<h2>Abstract</h2>
<div style="font-size:14px; text-align: justify;">
<p>
Current vision systems are trained on huge datasets, and these datasets come with costs: curation is expensive, they inherit human biases, and there are also concerns over privacy and usage rights. To counter the costs, interest has surged in learning from cheaper data sources, such as unlabeled images. In this paper we go a step further and ask if we can do away with datasets entirely, instead learning from procedural noise processes.
We investigate a suite of image generation models that produce images from simple random processes. These are then used as training data for a visual representation learner with a contrastive loss.
In particular, we study statistical image models, randomly initialized deep generative models, and procedural graphics models.
Our findings show that it is important for the noise to capture certain structural properties of real data but that good performance can be achieved even with processes that are far from realistic. We also find that diversity is a key property to learn good representations.
</p>
</div>

<center>
<h2>Game: real or noise?</h2>
<div style="border-width: 0; overflow: hidden">
    <iframe style="border-width: 0; overflow: hidden" src="game.html " width="100%" frameborder="0" scrolling="no" onload="resizeIframe(this)" title="Gallery"></iframe>
</div>

</center>

<hr>
<h2>Datasets</h2>
<div style="border-width: 0; overflow: hidden">
  <iframe style="border-width: 0; overflow: hidden" src="datasets_gallery.html " width="100%" frameborder="0" scrolling="no" onload="resizeIframe(this)" title="Gallery"></iframe>
</div>
<p>Randomly selected samples for each of the datasets presented in the paper.</p>
<br>

<hr>

<h2>Performance</h2>
<table border="0" cellspacing="0" cellpadding="0">
  <tr>
    <td align="center" valign="bottom" width=900>
        <img class="result" src="images/results_imagenet100.jpg" style="width: 100%">
    </td>
  </tr>
</table>
<p>Top-1 accuracy for the different models proposed and baselines for Imagenet-100. The horizontal
axis shows generative models sorted by performance. The two dashed lines represent approximated upper and
lower bounds in performance that one can expect from a system trained from samples of a generic generative
image model.</p>

<table border="0" cellspacing="0" cellpadding="0">
  <tr>
    <td align="center" valign="bottom" width=900>
        <img class="result" src="images/table_imagenet1k.jpg" style="width: 100%">
    </td>
  </tr>
</table>
<p>Performance of linear transfer for a ResNet50 pre-trained on different image models using MoCo-v2.</p>

</center>
<br>

<hr>
<center>
<h2>Feature visualizations</h2>
<div style="border-width: 0; overflow: hidden">
    <iframe style="border-width: 0; overflow: hidden" src="features_gallery.html " width="100%" frameborder="0" scrolling="no" onload="resizeIframe(this)" title="Gallery"></iframe>
  <p>Feature visualizations for randomly selected units in the third, fifth and seventh layer of an AlexNet-based encoder trained with each of the datasets.</p>
</div>

</center>

<hr>
<h3 style="margin-top: -1.6em"><code style="font-size: 15pt">bibtex</code> <span style="font-size: 14.5pt">entry</span></h3>
<div style="background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;padding-right: 4em;width: 95%">
<pre style="font-size: 10pt; margin: .3em 0px">
</pre>
</div>


<br>
<h2>Acknowledgements</h2>
<p style="font-size:14px; text-align: justify; padding-bottom: 15px">MB is supported by the LaCaixa Fellowship, JW is supported by a grant from Intel Corp.</p>

</div>

<style type="text/css" media="all">
.page__footer {
  /*float: left;*/
  padding-top: 1em;
  padding-bottom: 0.5em;
  margin-left: 0;
  margin-right: 0;
  width: 100%;
  clear: both;
  /* sticky footer fix start */
  /*position: absolute;*/
  bottom: 0;
  height: auto;
  /* sticky footer fix end */
  margin-top: 3em;
  color: #898c8f;
  background-color: #f2f3f3;
  padding-left: 0em;
  padding-right: 0em;
  max-width: 100%;
}

.page__footer .links {
  margin-left: auto;
  margin-right: auto;
  max-width: 1000px;
  /*padding: 0;*/
}

.page__footer .links .social-icons {
  padding-left: 0;
  text-align: left;
}
</style>

<div class="page__footer">
  <div class="links">
    <ul class="social-icons">
      <li style='display: inline-block; margin-right: 5px; font-style: bold'><strong>Links:</strong></li>
      <li style='display: inline-block; margin-right: 5px; font-style: normal;'><a href="https://accessibility.mit.edu"><i class="fa fa-fw fas fa-universal-access" aria-hidden="true"></i> Accessibility</a></li>
    </ul>
  </div>
</div>

</body>

</html>
